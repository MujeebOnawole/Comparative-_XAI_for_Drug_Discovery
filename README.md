# Explainable AI for Bioactivity Prediction: Multi-Architecture Comparative Study

## ğŸ“‹ Overview

This repository contains the complete codebase for a comparative study of explainable AI approaches in bioactivity prediction against *Staphylococcus aureus*. The project implements and compares three distinct machine learning architectures: **Random Forest**, **Convolutional Neural Networks (CNN)**, and **Relational Graph Convolutional Networks (RGCN)**, each with specialized explainability methods.

### ğŸ¯ Purpose & Applications

- **Research Reproducibility**: Full pipelines for training, validation, and testing of bioactivity prediction models
- **Model Comparison**: Side-by-side evaluation of three complementary ML approaches
- **Explainability Analysis**: Implementation of LIME, Grad-CAM, and substructure masking
- **Interactive Testing**: Ready-to-use Jupyter notebooks for model testing and visualization
- **Educational Resource**: Well-documented code for learning XAI in drug discovery

## ğŸ“Š Dataset

**Input**: `S_aureus.csv`  
- This file contains curated bioactivity data for 43,777 compounds against *Staphylococcus aureus*.
- **Note:** `S_aureus.csv` is **not included in this repository** due to file size.  
- **Access:** The dataset is available via Zenodo: [https://doi.org/10.5281/zenodo.17104898](https://doi.org/10.5281/zenodo.17104898)
- This CSV is used as the input to train all three model architectures.

### Key Dataset Features:
- **Molecular Properties**: MW, LogP, PSA, Lipinski descriptors
- **Activity Data**: MIC values, standardized activity classification
- **Chemical Diversity**: Broad chemical coverage
- **Quality Control**: Standardized SMILES, validated structures, consistent activity thresholds

## ğŸ—ï¸ Architecture Overview

| Model           | Molecular Representation | Explainability Method  | Key Strengths                        |
|-----------------|-------------------------|-----------------------|--------------------------------------|
| Random Forest   | Fragment Descriptors    | LIME                  | Interpretable features, fast training|
| CNN             | SMILES Sequences        | Grad-CAM              | Sequence patterns, character-level attention |
| RGCN            | Molecular Graphs        | Substructure Masking  | Relational information, chemical intuition |

## ğŸ“ Repository Structure

```
â”œâ”€â”€ Random_Forest/                  # Random Forest implementation
â”‚   â”œâ”€â”€ RF_LIME_Visualization.ipynb
â”‚   â”œâ”€â”€ descriptor.py
â”‚   â”œâ”€â”€ RF_CV.py
â”‚   â”œâ”€â”€ ML_SA.py
â”‚   â”œâ”€â”€ RF_test_evaluation.py
â”‚   â”œâ”€â”€ Functional_Group_mapping.txt
â”‚   â””â”€â”€ SA_FG_fragments.csv
â”‚
â”œâ”€â”€ CNN/                           
â”‚   â”œâ”€â”€ CNN_Grad_CAM_visual.ipynb
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ hyperparameter_opt.py
â”‚   â”œâ”€â”€ cross_validation.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ best_models.json
â”‚
â”œâ”€â”€ RGCN/                         
â”‚   â”œâ”€â”€ RGCN_SME_Visualization.ipynb
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ build_data.py
â”‚   â”œâ”€â”€ RGCN_CV.py
â”‚   â”œâ”€â”€ hyper_RGCN.py
â”‚   â”œâ”€â”€ rgcn_test_evaluation.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ ensemble_classification_attribution.csv
â”‚
â””â”€â”€ README.md                      # This file
```

> **Note:** All code files are provided directly in the repository (not zipped) for easy browsing.  
> **Pre-trained models, large output files, and the input dataset** are available on Zenodo: [https://doi.org/10.5281/zenodo.17104898](https://doi.org/10.5281/zenodo.17104898)

## ğŸš€ Quick Start: Interactive Notebooks

Each model folder includes a ready-to-use Jupyter notebook for immediate testing and visualization.

### 1ï¸âƒ£ Random Forest + LIME
```bash
cd Random_Forest
jupyter notebook RF_LIME_Visualization.ipynb
```
- LIME-based explanations for molecular fragments
- Interactive feature importance visualization

### 2ï¸âƒ£ CNN + Grad-CAM  
```bash
cd CNN
jupyter notebook CNN_Grad_CAM_visual.ipynb
```
- Grad-CAM heatmaps over SMILES
- Attention visualization for sequence patterns

### 3ï¸âƒ£ RGCN + Substructure Masking
```bash
cd RGCN
jupyter notebook RGCN_SME_Visualization.ipynb
```
- Murcko scaffold attribution analysis
- Interactive substructure highlighting

## ğŸ”§ Environment Setup

<... keep as in your original ...>

## ğŸ’» Model Training (Optional)

All notebooks can be retrained from scratch using the scripts provided in each folder.

## ğŸ“‹ Data Format Requirements

### Input Data Structure
```csv
COMPOUND_ID,PROCESSED_SMILES,TARGET,group
CHEMBL123,CC(=O)OC1=CC=CC=C1C(=O)O,1,training
CHEMBL456,CN1C=NC2=C1C(=O)N(C(=O)N2C)C,0,validation
```

## ğŸ”„ Reproducibility

- Deterministic training (fixed random seeds)
- Consistent data splits
- Pinned dependency versions

## ğŸ“Š Output Files & Results

- **Pre-trained model checkpoints, large output files, and the input dataset are available on Zenodo:**  
  [https://doi.org/10.5281/zenodo.17104898](https://doi.org/10.5281/zenodo.17104898)

## ğŸ“ Citation

If you use this code or data in your research, please cite:

```bibtex
@misc{xai-bioactivity-2025,
  title={Bridging the Explainability Gap in AI-Driven Drug Discovery: A Systematic Comparison of Interpretable Methods for Antimicrobial Prediction},
  author={Abdulmujeeb T. Onawole, Mark A. T. Blaskovich, Johannes Zuegg},
  year={2025},
  note={Working paper},
  publisher={Zenodo},
  doi={10.5281/zenodo.17104898}
}
```


